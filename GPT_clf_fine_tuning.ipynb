{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ9XrGRoNnVl"
   },
   "source": [
    "# Fine-tuning a GPT-4o-mini model for textual stance classification\n",
    "\n",
    "This model uses the JSONL datasets for stance classification created in FEVER_set_creation.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiY0hVYTNnVo"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast  # To safely evaluate the string representation of lists\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import argparse\n",
    "import json\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "from google.colab import drive, userdata\n",
    "drive.mount('/content/drive')\n",
    "# Adjust path as needed\n",
    "BASE_DIR = '/content/drive/My Drive/SUNY_Poly_DSA598/'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'datasets/FEVER/GPT_sets/')\n",
    "\n",
    "# --- Download NLTK sentence tokenizer if needed ---\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# --- Set up OpenAI API key ---\n",
    "api_key = userdata.get('openaikey')\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "def create_ft_job(job_name, train_path, val_path):\n",
    "    \"\"\"\n",
    "    Create a fine-tuning job using the OpenAI API.\n",
    "    \"\"\"\n",
    "    # Upload the training file\n",
    "    training_file = client.files.create(\n",
    "        file=open(train_path, \"rb\"),\n",
    "        purpose=\"fine-tune\",\n",
    "\n",
    "    )\n",
    "\n",
    "    # Upload the validation file\n",
    "    validation_file = client.files.create(\n",
    "        file=open(val_path, \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    # Create the fine-tuning job\n",
    "    fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "        training_file=training_file.id,\n",
    "        validation_file=validation_file.id,\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        seed=2025,\n",
    "    )\n",
    "    return fine_tuning_job.id\n",
    "\n",
    "def get_ft_job_list():\n",
    "    \"\"\"\n",
    "    Get the list of fine-tuning jobs using the OpenAI API.\n",
    "    \"\"\"\n",
    "    fine_tuning_jobs = client.fine_tuning.jobs.list()\n",
    "    return fine_tuning_jobs\n",
    "\n",
    "def get_ft_job_status(job_id):\n",
    "    \"\"\"\n",
    "    Get the status of a specific fine-tuning job using the OpenAI API.\n",
    "    \"\"\"\n",
    "    fine_tuning_job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    return fine_tuning_job\n",
    "\n",
    "def get_ft_job_results(job_id):\n",
    "    \"\"\"\n",
    "    Get the results of a specific fine-tuning job using the OpenAI API.\n",
    "    \"\"\"\n",
    "    fine_tuning_job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    return fine_tuning_job\n",
    "\n",
    "# Call the function to create a fine-tuning job\n",
    "clf_job_name = \"GPT_clf_paper_dev_train\"\n",
    "clf_train_path = os.path.join(DATA_DIR, 'GPT_clf_paper_dev_train/prompt_v1_segmented_n200_04-19_001.jsonl')\n",
    "clf_val_path = os.path.join(DATA_DIR, 'GPT_clf_paper_dev_valid/prompt_v1_segmented_n60_04-19_001.jsonl')\n",
    "clf_job_id = create_ft_job(clf_job_name, clf_train_path, clf_val_path)\n",
    "print(f\"Fine-tuning job created with ID: {clf_job_id}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
