{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05EjrBx7ENj6"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from google.colab import drive\n",
    "import gc\n",
    "\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kv0BFFXK59Aq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2518,
     "status": "ok",
     "timestamp": 1742063962089,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "yNeDrDm-GipK",
    "outputId": "195e7f72-95ac-479f-e8fe-d53db755721f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from nltk import RegexpParser\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "\n",
    "# Download the necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('treebank')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7IiY8MjTgyZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7wHT41emmSX"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "api_key = userdata.get('openaikey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7N1vsuEFnvta"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1742065932797,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "yi4Bf4jl3X7L",
    "outputId": "49729fca-ef37-4062-ea75-5e064d175648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742065932799,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "OjYHaKKQ6dqR",
    "outputId": "1c7d136d-0a6b-45ac-a900-42e5947750b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/SUNY_Poly_DSA598\n"
     ]
    }
   ],
   "source": [
    "%cd ./drive/My Drive/SUNY_Poly_DSA598/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1742065932880,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "p5P6aCEs6oL0",
    "outputId": "94059620-84bb-4089-e5cf-2f815087de52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_eval.ipynb  datasets  GPT_4o_mini_results\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjqMXr8E5Oze"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Loads a JSON Lines file into a list of Python objects.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:  # Specify encoding for safety\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))  # Parse each line individually\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izO4Q2p0mQAg"
   },
   "source": [
    "## LIAR Base Accuracy and Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1jMW5Mf3-dR"
   },
   "source": [
    "### LIAR Conversion to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCWMtsJJ8655"
   },
   "outputs": [],
   "source": [
    "liar_path = './datasets/LIAR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1742062873906,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "mKZHeVUsXfWG",
    "outputId": "af5f27cd-a6fc-46e5-9dd0-6b23a9b5f5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/SUNY_Poly_DSA598\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4298,
     "status": "ok",
     "timestamp": 1741741761144,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "v7wlP5Zz8nyW",
    "outputId": "f1ab7fcd-bc86-41b3-e15e-082b65f000b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAR data conversion to JSONL completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liar_label_mapping = {\n",
    "    \"true\": \"1\",\n",
    "    \"mostly-true\": \"1\",\n",
    "    \"half-true\": \"1\",\n",
    "    \"false\": \"0\",\n",
    "    \"pants-fire\": \"0\",\n",
    "    \"barely-true\": \"0\"\n",
    "}\n",
    "\n",
    "def convert_liar_tsv_to_jsonl(tsv_filepath, jsonl_filepath):\n",
    "    \"\"\"\n",
    "    Converts a LIAR TSV file to a JSONL file for OpenAI fine-tuning.\n",
    "\n",
    "    Args:\n",
    "        tsv_filepath (str): Path to the input TSV file.\n",
    "        jsonl_filepath (str): Path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(tsv_filepath, sep='\\t', header=None)\n",
    "    data_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        label = row[1]\n",
    "        statement = row[2]\n",
    "\n",
    "        mapped_label = liar_label_mapping.get(label) # Use .get() for safety in case of unknown labels\n",
    "\n",
    "        ########## VARIABLES – SUBJECTIVE PROMPTS ##########\n",
    "        sys_msg = \"You are a fact checking classifier. Classify the truthfulness of the text: '1' if the statement is true, '0' if the statement is false\"\n",
    "        user_msg = \"Classify the truthfulness of the following text out of the following categories: '1' if the statement is true, '0' if the statement is false. Do not use any other labels:\\n\\n\" + statement\n",
    "        assistant_msg = mapped_label\n",
    "        ###################################################\n",
    "\n",
    "        if mapped_label: # Only include data points with mapped labels\n",
    "          data_list.append({\n",
    "            \"messages\": [\n",
    "              {\"role\": \"system\", \"content\": sys_msg},\n",
    "              {\"role\": \"user\", \"content\": user_msg},\n",
    "              {\"role\": \"assistant\", \"content\": assistant_msg}\n",
    "            ]\n",
    "\t\t\t})\n",
    "\n",
    "    with open(jsonl_filepath, 'w') as f:\n",
    "        for data_item in data_list:\n",
    "            json.dump(data_item, f)\n",
    "            f.write('\\n') # Write each JSON object on a new line\n",
    "\n",
    "\n",
    "# Example usage to convert train, valid, and test sets:\n",
    "convert_liar_tsv_to_jsonl(liar_path + 'train.tsv', liar_path + 'liar_train_user_prompt.jsonl')\n",
    "convert_liar_tsv_to_jsonl(liar_path + 'valid.tsv', liar_path + 'liar_valid_user_prompt.jsonl')\n",
    "convert_liar_tsv_to_jsonl(liar_path + 'test.tsv', liar_path + 'liar_test_user_prompt.jsonl')\n",
    "\n",
    "print(\"LIAR data conversion to JSONL completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-s5jP5Z7EdS"
   },
   "outputs": [],
   "source": [
    "liar_train = load_jsonl(f'{liar_path}liar_train_user_prompt.jsonl')\n",
    "liar_valid = load_jsonl(f'{liar_path}liar_valid_user_prompt.jsonl')\n",
    "liar_test = load_jsonl(f'{liar_path}liar_test_user_prompt.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741741765675,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "2w87mJZ-5aO4",
    "outputId": "b3f02d25-c5a8-4752-8a9c-78758f0e4dd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liar_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiNKBLzKnUgp"
   },
   "source": [
    "### Check GPT-4o-mini's base fact-checking capabilities on LIAR (training set examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741403774963,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 300
    },
    "id": "EYspXY4DvD4q",
    "outputId": "2e7a8494-6216-4327-d243-a99850f1e395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages: [{'role': 'system', 'content': \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"}, {'role': 'user', 'content': 'Says the Annies List political group supports third-trimester abortions on demand.'}, {'role': 'assistant', 'content': '0'}]\n",
      "messages: [{'role': 'system', 'content': \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"}, {'role': 'user', 'content': 'When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.'}, {'role': 'assistant', 'content': '1'}]\n",
      "messages: [{'role': 'system', 'content': \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"}, {'role': 'user', 'content': 'Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"'}, {'role': 'assistant', 'content': '1'}]\n",
      "messages: [{'role': 'system', 'content': \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"}, {'role': 'user', 'content': 'Health care reform legislation is likely to mandate free sex change surgeries.'}, {'role': 'assistant', 'content': '0'}]\n",
      "messages: [{'role': 'system', 'content': \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"}, {'role': 'user', 'content': 'The economic turnaround started at the end of my term.'}, {'role': 'assistant', 'content': '1'}]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few  nested objects\n",
    "for item, i in zip(liar_train, range(5)):\n",
    "  for key in (item.keys()):\n",
    "    print(key + ': ' + str(liar_train[i][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFaX_OBpKcpy"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Load all the files starting with 'meta' in the GPT_4o_mini_results directory and run tokenize_text on the appropriate columns (this was a mistake in the original code)\n",
    "'''\n",
    "for file in os.listdir('GPT_4o_mini_results/liar_test'):\n",
    "    if file.startswith('meta'):\n",
    "        df = pd.read_csv(os.path.join('GPT_4o_mini_results', file))\n",
    "        df['usr_msg_num_tokens'] = df['user_msg'].apply(lambda x: tokenize_text(x)[0])\n",
    "        df['usr_msg_avg_wrd_len'] = df['user_msg'].apply(lambda x: tokenize_text(x)[1])\n",
    "        df['sys_msg_num_tokens'] = df['sys_msg'].apply(lambda x: tokenize_text(x)[0])\n",
    "        df['sys_msg_avg_wrd_len'] = df['sys_msg'].apply(lambda x: tokenize_text(x)[1])\n",
    "\n",
    "        df.to_csv(os.path.join('GPT_4o_mini_results/liar_test', file), index=False)\n",
    "\n",
    "# Load all the files starting with 'results' in the GPT_4o_mini_results directory and run tokenize_text on the appropriate columns\n",
    "for file in os.listdir('GPT_4o_mini_results'):\n",
    "    if file.startswith('results'):\n",
    "        df = pd.read_csv(os.path.join('GPT_4o_mini_results', file))\n",
    "        df['claim_num_tokens'] = df['claim'].apply(lambda x: tokenize_text(x)[0])\n",
    "        df['claim_avg_wrd_len'] = df['claim'].apply(lambda x: tokenize_text(x)[1])\n",
    "        df.to_csv(os.path.join('GPT_4o_mini_results', file), index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dte_7FvtGgcA"
   },
   "outputs": [],
   "source": [
    "def fact_check_claim(claim, temp, prompt):\n",
    "\n",
    "  chat_completion = client.chat.completions.create(\n",
    "\t\t  messages=[\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t  \"content\": prompt['system_message']\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t  \"role\": \"user\",\n",
    "\t\t\t\t  \"content\": prompt['user_message'] + \"\\n\\n\" + claim\n",
    "\t\t\t\t},\n",
    "\t\t  ],\n",
    "\t\ttemperature=temp,\n",
    "\t\tmodel=\"gpt-4o-mini-2024-07-18\",\n",
    "\t\t)\n",
    "\n",
    "  return chat_completion.choices[0].message.content\n",
    "\n",
    "# Function to tokenize text and return number of tokens and semantic complexity\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text and returns the number of tokens and semantic complexity.\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Calculate the number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    # Calculate semantic complexity using a simple heuristic (e.g., average word length)\n",
    "    avg_word_length = sum(len(word) for word in tokens) / num_tokens if num_tokens > 0 else 0\n",
    "\n",
    "    return num_tokens, avg_word_length\n",
    "\n",
    "\n",
    "def run_gpt4o_raw(df, usr_msg, sys_msg, temp, n, rand_state):\n",
    "    print(f\"Prompting GPT with {n} claims, and the following parameters:\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print(f\"Random State: {rand_state}\")\n",
    "\n",
    "    # Preprocess the dataframe\n",
    "    df = df[['messages']]\n",
    "\n",
    "    df['claim'] = df['messages'].apply(lambda x: x[1]['content'])\n",
    "    df['label'] = df['messages'].apply(lambda x: x[2]['content'])\n",
    "\n",
    "    df = df[['claim', 'label']]\n",
    "\n",
    "    df = df.sample(frac=1, random_state=rand_state).reset_index(drop=True)\n",
    "    df = df.iloc[:n]\n",
    "\n",
    "    # Get the number of tokens and semantic complexity for the system message and user message and set a new column for each\n",
    "    sys_msg_num_tokens, sys_msg_semantic_complexity = tokenize_text(sys_msg)\n",
    "    usr_msg_num_tokens, usr_msg_semantic_complexity = tokenize_text(usr_msg)\n",
    "\n",
    "    print(f\"Number of tokens in user message: {usr_msg_num_tokens}\")\n",
    "    print(f\"Average word length in user message: {usr_msg_semantic_complexity}\")\n",
    "\n",
    "    print(f\"Number of tokens in system message: {sys_msg_num_tokens}\")\n",
    "    print(f\"Average word length in system message: {sys_msg_semantic_complexity}\")\n",
    "\n",
    "    df['claim_num_tokens'] = df['claim'].apply(lambda x: tokenize_text(x)[0])\n",
    "    df['claim_avg_wrd_len'] = df['claim'].apply(lambda x: tokenize_text(x)[1])\n",
    "\n",
    "    print(f\"Total number of claims: {len(df)}\")\n",
    "    print(f\"Total number of tokens in claims: {df['claim_num_tokens'].sum()}\")\n",
    "\n",
    "    prompt = { 'system_message': sys_msg, 'user_message': usr_msg }\n",
    "\n",
    "    df['model_prediction'] = df['claim'].apply(lambda x: fact_check_claim(x, temp, prompt))\n",
    "\n",
    "    gpt4o_raw_acc = accuracy_score(df['label'], df['model_prediction'])\n",
    "    gpt4o_raw_kappa = cohen_kappa_score(df['label'], df['model_prediction'])\n",
    "\n",
    "    results = pd.DataFrame(columns=['temp', 'n', 'rand_state', 'acc', 'kappa', 'sys_msg', 'user_msg', 'sys_msg_num_tokens', 'sys_msg_avg_wrd_len', 'usr_msg_num_tokens', 'usr_msg_avg_wrd_len'])\n",
    "    results.loc[0] = [temp, n, rand_state, gpt4o_raw_acc, gpt4o_raw_kappa, prompt['system_message'], prompt['user_message'], sys_msg_num_tokens, sys_msg_semantic_complexity, usr_msg_num_tokens, usr_msg_semantic_complexity]\n",
    "\n",
    "    return results, df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741744590189,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "RvJWUjXs-_Z8",
    "outputId": "3ec31aba-f806-4a64-d850-4a847264fd7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/SUNY_Poly_DSA598\n"
     ]
    }
   ],
   "source": [
    "#%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LDQn4kT_Mim"
   },
   "outputs": [],
   "source": [
    "# os.mkdir('GPT_4o_mini_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1742063739289,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "VH5aEknFFXUm",
    "outputId": "c3052c2e-b6b0-48ea-d859-52838fb9ac25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-15\n"
     ]
    }
   ],
   "source": [
    "# Set the date of the test (today)\n",
    "now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=-5)))\n",
    "date_fmt = now.strftime(\"%m-%d\")\n",
    "print(date_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 28078,
     "status": "ok",
     "timestamp": 1742063782832,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "Vk8XT46h8s19",
    "outputId": "b9442e33-f339-40fc-c382-fbda4f3736e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in GPT_4o_mini_results: 48\n",
      "Run count: 25\n",
      "Prompting GPT with 65 claims, and the following parameters:\n",
      "Temperature: 0.9\n",
      "Random State: 100\n",
      "Number of tokens in user message: 50\n",
      "Average word length in user message: 3.4\n",
      "Number of tokens in system message: 34\n",
      "Average word length in system message: 4.5588235294117645\n",
      "Total number of claims: 65\n",
      "Total number of tokens in claims: 3824\n",
      "Saved results to GPT_4o_mini_results/liar_test/025_03-15.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"gpt4oMini_raw_tests\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9,\n        \"max\": 0.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 65,\n        \"max\": 65,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rand_state\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 100,\n        \"max\": 100,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5538461538461539,\n        \"max\": 0.5538461538461539,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5538461538461539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.10195331110052408,\n        \"max\": 0.10195331110052408,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.10195331110052408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"You are an investigative agent tasked with verifying the truthfulness of claims. If you predict correctly, you will save someone's life. If you predict incorrectly, someone will die.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_msg\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Think logically about the structure of the sentence; does it sound like a lie?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg_num_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 34,\n        \"max\": 34,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg_avg_wrd_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.5588235294117645,\n        \"max\": 4.5588235294117645,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.5588235294117645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usr_msg_num_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 50,\n        \"max\": 50,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usr_msg_avg_wrd_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.4,\n        \"max\": 3.4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"liar_test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "gpt4oMini_raw_tests"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-7348c221-b35a-40ac-a4e7-dcb6a4b0248c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>n</th>\n",
       "      <th>rand_state</th>\n",
       "      <th>acc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>sys_msg</th>\n",
       "      <th>user_msg</th>\n",
       "      <th>sys_msg_num_tokens</th>\n",
       "      <th>sys_msg_avg_wrd_len</th>\n",
       "      <th>usr_msg_num_tokens</th>\n",
       "      <th>usr_msg_avg_wrd_len</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.101953</td>\n",
       "      <td>You are an investigative agent tasked with ver...</td>\n",
       "      <td>Classify the truthfulness of the text out of t...</td>\n",
       "      <td>34</td>\n",
       "      <td>4.558824</td>\n",
       "      <td>50</td>\n",
       "      <td>3.4</td>\n",
       "      <td>liar_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7348c221-b35a-40ac-a4e7-dcb6a4b0248c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7348c221-b35a-40ac-a4e7-dcb6a4b0248c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7348c221-b35a-40ac-a4e7-dcb6a4b0248c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_09f5b301-e525-4b95-aefb-731c91e8e723\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('gpt4oMini_raw_tests')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_09f5b301-e525-4b95-aefb-731c91e8e723 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('gpt4oMini_raw_tests');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   temp   n  rand_state       acc     kappa  \\\n",
       "0   0.9  65         100  0.553846  0.101953   \n",
       "\n",
       "                                             sys_msg  \\\n",
       "0  You are an investigative agent tasked with ver...   \n",
       "\n",
       "                                            user_msg  sys_msg_num_tokens  \\\n",
       "0  Classify the truthfulness of the text out of t...                  34   \n",
       "\n",
       "   sys_msg_avg_wrd_len  usr_msg_num_tokens  usr_msg_avg_wrd_len dataset_name  \n",
       "0             4.558824                  50                  3.4    liar_test  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine test number from directory length\n",
    "num_files = len(os.listdir('GPT_4o_mini_results/liar_test'))\n",
    "print(f\"Number of files in GPT_4o_mini_results: {num_files}\")\n",
    "run_count = (num_files // 2) + 1\n",
    "run_count_str = str(run_count).zfill(3)\n",
    "print(f\"Run count: {run_count}\")\n",
    "\n",
    "liar_test_df = pd.DataFrame(liar_test)\n",
    "\n",
    "# Set these\n",
    "temp = .90\n",
    "n = 65\n",
    "rand_state = 100\n",
    "sys_msg = \"You are an investigative agent tasked with verifying the truthfulness of claims. If you predict correctly, you will save someone's life. If you predict incorrectly, someone will die.\"\n",
    "user_msg = \"Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Think logically about the structure of the sentence; does it sound like a lie?\"\n",
    "\n",
    "gpt4oMini_raw_tests, results_df = run_gpt4o_raw(liar_test_df, user_msg, sys_msg, temp, n, rand_state)\n",
    "\n",
    "# Set this\n",
    "gpt4oMini_raw_tests['dataset_name'] = 'liar_test'\n",
    "\n",
    "gpt4oMini_raw_tests.to_csv(f'GPT_4o_mini_results/liar_test/meta_{run_count_str}_{date_fmt}.csv', index=False)\n",
    "results_df.to_csv(f'GPT_4o_mini_results/liar_test/results_{run_count_str}_{date_fmt}.csv', index=False)\n",
    "\n",
    "print(f\"Saved results to GPT_4o_mini_results/liar_test/{run_count_str}_{date_fmt}.csv\")\n",
    "\n",
    "gpt4oMini_raw_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1742064705881,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "_VvCaSNABc3O",
    "outputId": "b4b85a84-d6a3-41ce-81c3-610b8b859de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing meta_013_03-11.csv\n",
      "Processing meta_005_03-11.csv\n",
      "Processing meta_008_03-11.csv\n",
      "Processing meta_010_03-11.csv\n",
      "Processing meta_002_03-11.csv\n",
      "Processing meta_006_03-11.csv\n",
      "Processing meta_003_03-11.csv\n",
      "Processing meta_009_03-11.csv\n",
      "Processing meta_001_03-11.csv\n",
      "Processing meta_007_03-11.csv\n",
      "Processing meta_004_03-11.csv\n",
      "Processing meta_012_03-11.csv\n",
      "Processing meta_011_03-11.csv\n",
      "Processing meta_014_03-12.csv\n",
      "Processing meta_015_03-12.csv\n",
      "Processing meta_016_03-12.csv\n",
      "Processing meta_017_03-12.csv\n",
      "Processing meta_018_03-12.csv\n",
      "Processing meta_019_03-12.csv\n",
      "Processing meta_020_03-12.csv\n",
      "Processing meta_021_03-12.csv\n",
      "Processing meta_022_03-12.csv\n",
      "Processing meta_023_03-12.csv\n",
      "Processing meta_024_03-12.csv\n",
      "Processing meta_025_03-15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-94b997c00e1a>:12: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"68538a89-8566-482e-a6a8-ac6ae141d6b8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"68538a89-8566-482e-a6a8-ac6ae141d6b8\")) {                    Plotly.newPlot(                        \"68538a89-8566-482e-a6a8-ac6ae141d6b8\",                        [{\"customdata\":[[50]],\"hovertemplate\":\"model_id=013\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"013\",\"marker\":{\"color\":\"#636EFA\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"013\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.1],\"xaxis\":\"x\",\"y\":[0.44],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=005\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"005\",\"marker\":{\"color\":\"#EF553B\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"005\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.6],\"xaxis\":\"x\",\"y\":[0.4857142857142857],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=008\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"008\",\"marker\":{\"color\":\"#00CC96\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"008\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.5142857142857142],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=010\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"010\",\"marker\":{\"color\":\"#AB63FA\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"010\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.54],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=002\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"002\",\"marker\":{\"color\":\"#FFA15A\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"002\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.0],\"xaxis\":\"x\",\"y\":[0.5142857142857142],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=006\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"006\",\"marker\":{\"color\":\"#19D3F3\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"006\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.9],\"xaxis\":\"x\",\"y\":[0.4285714285714285],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=003\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"003\",\"marker\":{\"color\":\"#FF6692\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"003\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.8],\"xaxis\":\"x\",\"y\":[0.4285714285714285],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=009\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"009\",\"marker\":{\"color\":\"#B6E880\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"009\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.05],\"xaxis\":\"x\",\"y\":[0.4],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=001\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"001\",\"marker\":{\"color\":\"#FF97FF\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"001\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.8],\"xaxis\":\"x\",\"y\":[0.4285714285714285],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=007\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"007\",\"marker\":{\"color\":\"#FECB52\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"007\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.1],\"xaxis\":\"x\",\"y\":[0.4571428571428571],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[35]],\"hovertemplate\":\"model_id=004\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"004\",\"marker\":{\"color\":\"#636EFA\",\"size\":[35],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"004\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.7],\"xaxis\":\"x\",\"y\":[0.4571428571428571],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=012\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"012\",\"marker\":{\"color\":\"#EF553B\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"012\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.0],\"xaxis\":\"x\",\"y\":[0.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=011\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"011\",\"marker\":{\"color\":\"#00CC96\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"011\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.9],\"xaxis\":\"x\",\"y\":[0.44],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=014\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"014\",\"marker\":{\"color\":\"#AB63FA\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"014\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.1],\"xaxis\":\"x\",\"y\":[0.54],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=015\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"015\",\"marker\":{\"color\":\"#FFA15A\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"015\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=016\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"016\",\"marker\":{\"color\":\"#19D3F3\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"016\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.54],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=017\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"017\",\"marker\":{\"color\":\"#FF6692\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"017\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.52],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=018\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"018\",\"marker\":{\"color\":\"#B6E880\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"018\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.58],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=019\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"019\",\"marker\":{\"color\":\"#FF97FF\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"019\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.56],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=020\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"020\",\"marker\":{\"color\":\"#FECB52\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"020\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.54],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=021\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"021\",\"marker\":{\"color\":\"#636EFA\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"021\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.52],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=022\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"022\",\"marker\":{\"color\":\"#EF553B\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"022\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.95],\"xaxis\":\"x\",\"y\":[0.58],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[50]],\"hovertemplate\":\"model_id=023\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"023\",\"marker\":{\"color\":\"#00CC96\",\"size\":[50],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"023\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.9],\"xaxis\":\"x\",\"y\":[0.58],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[65]],\"hovertemplate\":\"model_id=024\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"024\",\"marker\":{\"color\":\"#AB63FA\",\"size\":[65],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"024\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.9],\"xaxis\":\"x\",\"y\":[0.6],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[65]],\"hovertemplate\":\"model_id=025\\u003cbr\\u003eTemperature=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cbr\\u003en=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"025\",\"marker\":{\"color\":\"#FFA15A\",\"size\":[65],\"sizemode\":\"area\",\"sizeref\":0.1625,\"symbol\":\"circle\",\"line\":{\"color\":\"black\",\"width\":2}},\"mode\":\"markers\",\"name\":\"025\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.9],\"xaxis\":\"x\",\"y\":[0.5538461538461539],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Temperature\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy\"}},\"legend\":{\"title\":{\"text\":\"model_id\"},\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"title\":{\"text\":\"Accuracy vs Temperature by Model ID\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('68538a89-8566-482e-a6a8-ac6ae141d6b8');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all the files starting with 'meta' in the GPT_4o_mini_results directory and plot the 'acc' column on the y  with  temp on the x\n",
    "all_time_metrics = pd.DataFrame(columns=['temp', 'n', 'rand_state', 'acc', 'kappa', 'sys_msg', 'user_msg', 'model_id'])\n",
    "for file in os.listdir('GPT_4o_mini_results/liar_test'):\n",
    "    if file.startswith('meta'):\n",
    "        df = pd.read_csv(os.path.join('GPT_4o_mini_results/liar_test', file))\n",
    "        # Fill na in all colmumns with pd.NA\n",
    "        df = df.fillna(pd.NA)\n",
    "        df['temp'] = df['temp'].astype(float)\n",
    "        df['n'] = df['n'].astype(int)\n",
    "        df['model_id'] = file.split('_')[1]\n",
    "        print(f\"Processing {file}\")\n",
    "        all_time_metrics = pd.concat([all_time_metrics, df])\n",
    "\n",
    "# Convert the 'n' column to an int\n",
    "all_time_metrics['n'] = all_time_metrics['n'].astype(int)\n",
    "\n",
    "# Plot the accuracy vs tempeture by model_id with plotly (scatter plot), size by 'n'\n",
    "fig = px.scatter(all_time_metrics, x='temp', y='acc', color='model_id', size='n',\n",
    "                 hover_data=['temp', 'acc', 'n'],\n",
    "                 title='Accuracy vs Temperature by Model ID',\n",
    "                 labels={'temp': 'Temperature', 'acc': 'Accuracy'},\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "# Update traces to make the points bigger and outlined in black\n",
    "fig.update_traces(marker=dict(line=dict(width=2, color='black')), selector=dict(mode='markers'))\n",
    "fig.update_layout(xaxis_title='Temperature', yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1742064863594,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "av2l6RiGGqA_",
    "outputId": "d70202dd-8170-444c-c37c-083b459bbb37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"all_time_metrics\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11456439237389603,\n        \"min\": 0.6,\n        \"max\": 1.1,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.95,\n          0.7,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 35,\n        \"max\": 65,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          65,\n          50,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rand_state\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 100,\n        \"max\": 100,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05730529462320944,\n        \"min\": 0.4,\n        \"max\": 0.6,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.4285714285714285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11028496951616423,\n        \"min\": -0.1912479740680712,\n        \"max\": 0.1982922201138519,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.1982922201138519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"You are a fact checking classifier.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_msg\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Think logically about the structure of the sentence; does it sound like a lie?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"liar_test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg_num_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.90724257573165,\n        \"min\": 0.0,\n        \"max\": 34.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sys_msg_avg_wrd_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1526346385989643,\n        \"min\": 0.0,\n        \"max\": 4.5588235294117645,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usr_msg_num_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.425729530566939,\n        \"min\": 41.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          50.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usr_msg_avg_wrd_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1422124797945227,\n        \"min\": 3.1219512195121952,\n        \"max\": 3.515625,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "all_time_metrics"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a4d86bc0-ba52-441c-b159-247659ccedf3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>n</th>\n",
       "      <th>rand_state</th>\n",
       "      <th>acc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>sys_msg</th>\n",
       "      <th>user_msg</th>\n",
       "      <th>model_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sys_msg_num_tokens</th>\n",
       "      <th>sys_msg_avg_wrd_len</th>\n",
       "      <th>usr_msg_num_tokens</th>\n",
       "      <th>usr_msg_avg_wrd_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.198292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classify the truthfulness of the text out of t...</td>\n",
       "      <td>024</td>\n",
       "      <td>liar_test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d86bc0-ba52-441c-b159-247659ccedf3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a4d86bc0-ba52-441c-b159-247659ccedf3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a4d86bc0-ba52-441c-b159-247659ccedf3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   temp   n rand_state  acc     kappa sys_msg  \\\n",
       "0   0.9  65        100  0.6  0.198292     NaN   \n",
       "\n",
       "                                            user_msg model_id dataset_name  \\\n",
       "0  Classify the truthfulness of the text out of t...      024    liar_test   \n",
       "\n",
       "   sys_msg_num_tokens  sys_msg_avg_wrd_len  usr_msg_num_tokens  \\\n",
       "0                 0.0                  0.0                50.0   \n",
       "\n",
       "   usr_msg_avg_wrd_len  \n",
       "0                  3.4  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model by accuracy\n",
    "# Sort the dataframe by acc\n",
    "all_time_metrics = all_time_metrics.sort_values(by=['acc'], ascending=False)\n",
    "# Print the first row\n",
    "all_time_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742063831991,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "_nDymB1YLKAV",
    "outputId": "d89f5407-d931-4ef7-ea4f-cd9806df2a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['model_prediction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741741862172,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "MaQ3IT2-Lguy",
    "outputId": "9a075337-ae17-4d8e-da3d-a4e68e618e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before dropping misclassifications: 35\n",
      "Length after dropping misclassifications: 35\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'model_prediction' is not 1 or 0\n",
    "print(f\"Length before dropping misclassifications: {len(liar_valid_df)}\")\n",
    "liar_valid_df = liar_valid_df[liar_valid_df['model_prediction'].isin(['1', '0'])]\n",
    "print(f\"Length after dropping misclassifications: {len(liar_valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742063835475,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "Wa-ywJSvG5P0",
    "outputId": "b230f2a6-c24c-4c17-9a0f-a7dc07501b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51        28\n",
      "           1       0.62      0.57      0.59        37\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.55      0.55      0.55        65\n",
      "weighted avg       0.56      0.55      0.56        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report from the model's predictions\n",
    "print(classification_report(results_df['label'], results_df['model_prediction']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDJ9jDWHnZul"
   },
   "source": [
    "### Fine-tune GPT-4o-mini on LIAR train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3129,
     "status": "ok",
     "timestamp": 1741403526847,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 300
    },
    "id": "pXexahuuAnin",
    "outputId": "e03a3b59-a44a-4bae-be3f-c30aa01560d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job started with ID: ftjob-QTgmjez0GvcpC2pc3JWH3RGb\n"
     ]
    }
   ],
   "source": [
    "train_path = 'LIAR/liar_train.jsonl'\n",
    "val_path = 'LIAR/liar_valid.jsonl'\n",
    "\n",
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(train_path, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Upload the validation file\n",
    "validation_file = client.files.create(\n",
    "    file=open(val_path, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Create the fine-tuning job\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=2025,\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job started with ID: {fine_tuning_job.id}\")\n",
    "# ftjob-fnGzvRpBN2747hKB8vNQbBUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1741407246816,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 300
    },
    "id": "H8hmeUPbB_Dn",
    "outputId": "dfb115bd-c4a4-488e-e32d-683a02950765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring fine-tuning job: ftjob-QTgmjez0GvcpC2pc3JWH3RGb\n",
      "Job Status: succeeded\n",
      "Fine-tuning job succeeded! Fine-tuned model ID: ft:gpt-4o-mini-2024-07-18:personal::B8fgxGeb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fine_tuning_job_id = \"ftjob-QTgmjez0GvcpC2pc3JWH3RGb\"\n",
    "\n",
    "print(f\"Monitoring fine-tuning job: {fine_tuning_job_id}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        job_status = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "        status = job_status.status\n",
    "        print(f\"Job Status: {status}\")\n",
    "\n",
    "        if status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "            if status == \"succeeded\":\n",
    "                fine_tuned_model_id = job_status.fine_tuned_model\n",
    "                print(f\"Fine-tuning job succeeded! Fine-tuned model ID: {fine_tuned_model_id}\")\n",
    "            else:\n",
    "                print(f\"Fine-tuning job ended with status: {status}\")\n",
    "            break # Exit the loop when the job is done\n",
    "\n",
    "        time.sleep(240) # Check status every 4 minutes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving job status: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AiF2ebp4byl"
   },
   "source": [
    "### Evalute GPT-4o-mini's fact-checking capabilities on LIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1741657653444,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "NuERKZYhnu3j",
    "outputId": "6179a69c-88b7-4070-a391-37b3d10ab4ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model name: ft:gpt-4o-mini-2024-07-18:personal::B8fgxGeb\n",
      "Training Job Details:\n",
      "FineTuningJob(id='ftjob-QTgmjez0GvcpC2pc3JWH3RGb', created_at=1741403526, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::B8fgxGeb', finished_at=1741406585, hyperparameters=Hyperparameters(batch_size=13, learning_rate_multiplier=1.8, n_epochs=2), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-kl11ePoaunzKiXcGWah4MsfM', result_files=['file-JFWHrVnqWXZfArATeBuiya'], seed=2025, status='succeeded', trained_tokens=1730122, training_file='file-6jg5yJTKdd6HUJx4dJCtth', validation_file='file-GLcbhmj4NmyPyvqBfXtiR7', estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=13, learning_rate_multiplier=1.8, n_epochs=2)), type='supervised'), user_provided_suffix=None, metadata=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tuning_job_id = \"ftjob-QTgmjez0GvcpC2pc3JWH3RGb\"\n",
    "# Retrive the model and evaluate it\n",
    "fine_tuned_model = client.fine_tuning.jobs.retrieve(fine_tuning_job_id).fine_tuned_model\n",
    "print(f\"Fine-tuned model name: {fine_tuned_model}\")\n",
    "\n",
    "# Retrieve fine-tuning job details\n",
    "fine_tuning_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "print(f\"Training Job Details:\\n{fine_tuning_job}\")\n",
    "\n",
    "# FineTuningJob(id='ftjob-dkIRTFJOA6Qh11CdmZomcbzH', created_at=1733026293, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZWBdadz', finished_at=1733028567, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-kl11ePoaunzKiXcGWah4MsfM', result_files=['file-Q8EaHCC7AuVGiVSuheYoeS'], seed=42, status='succeeded', trained_tokens=126372, training_file='file-18zW8MGB58XZC5wR98V32N', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
    "result_file = fine_tuning_job.result_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyQB5SUyoi1d"
   },
   "outputs": [],
   "source": [
    "liar_test_df = pd.DataFrame(liar_test)\n",
    "liar_test_df = liar_test_df[['messages']]\n",
    "liar_test_df['claim'] = liar_test_df['messages'].apply(lambda x: x[1]['content'])\n",
    "liar_test_df['label'] = liar_test_df['messages'].apply(lambda x: x[2]['content'])\n",
    "liar_test_df = liar_test_df[['claim', 'label']]\n",
    "liar_test_df['model_prediction'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1741657821362,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 240
    },
    "id": "6d2vDKWL5Tv6",
    "outputId": "706082c2-95cd-4e98-c921-56c6954db43f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"liar_test_df\",\n  \"rows\": 1267,\n  \"fields\": [\n    {\n      \"column\": \"claim\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1267,\n        \"samples\": [\n          \"On recess appointments.\",\n          \"White men account for 69 percent of those arrested for violent crimes.\",\n          \"When these same Republicans - including Mr. Boehner - were in charge, the number of earmarks and pet projects went up, not down.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_prediction\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "liar_test_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-510b5e3d-776f-480e-b72b-46e33978d53d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>Says his budget provides the highest state fun...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Ive been here almost every day.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>In the early 1980s, Sen. Edward Kennedy secret...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>Says an EPA permit languished under Strickland...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>Says the governor is going around the state ta...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-510b5e3d-776f-480e-b72b-46e33978d53d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-510b5e3d-776f-480e-b72b-46e33978d53d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-510b5e3d-776f-480e-b72b-46e33978d53d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-09fae61e-bd59-4e05-8a15-a7592a81e737\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09fae61e-bd59-4e05-8a15-a7592a81e737')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-09fae61e-bd59-4e05-8a15-a7592a81e737 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_ac2365b3-4598-4c42-a455-c7aa388fe003\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('liar_test_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_ac2365b3-4598-4c42-a455-c7aa388fe003 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('liar_test_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  claim label model_prediction\n",
       "0     Building a wall on the U.S.-Mexico border will...     1                 \n",
       "1     Wisconsin is on pace to double the number of l...     0                 \n",
       "2     Says John McCain has done nothing to help the ...     0                 \n",
       "3     Suzanne Bonamici supports a plan that will cut...     1                 \n",
       "4     When asked by a reporter whether hes at the ce...     0                 \n",
       "...                                                 ...   ...              ...\n",
       "1262  Says his budget provides the highest state fun...     1                 \n",
       "1263                    Ive been here almost every day.     0                 \n",
       "1264  In the early 1980s, Sen. Edward Kennedy secret...     0                 \n",
       "1265  Says an EPA permit languished under Strickland...     0                 \n",
       "1266  Says the governor is going around the state ta...     0                 \n",
       "\n",
       "[1267 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGJQCZhCoxMw"
   },
   "outputs": [],
   "source": [
    "model_id = 'ft:gpt-4o-mini-2024-07-18:personal::B8fgxGeb'\n",
    "\n",
    "# Function to label data using any model\n",
    "def label_data(df, model_name):\n",
    "    labeled_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a fact checking classifier. Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Classify the truthfulness of the text out of the following categories: '1' (if the claim is true), '0' (if the claim is false). Do not use any other labels.\\n\\n{row['claim']}\"},\n",
    "            ]\n",
    "        )\n",
    "        label = completion.choices[0].message.content\n",
    "        labeled_data.append ({\n",
    "            \"claim\": row['claim'],\n",
    "            \"label\": row['label'],\n",
    "            \"model_prediction\": label\n",
    "        })\n",
    "    return pd.DataFrame(labeled_data)\n",
    "# Label the validation set using the fine-tuned model\n",
    "\n",
    "liar_test_df = pd.DataFrame(liar_test)\n",
    "liar_test_df = liar_test_df[['messages']]\n",
    "liar_test_df['claim'] = liar_test_df['messages'].apply(lambda x: x[1]['content'])\n",
    "liar_test_df['label'] = liar_test_df['messages'].apply(lambda x: x[2]['content'])\n",
    "liar_test_df = liar_test_df[['claim', 'label']]\n",
    "liar_test_df['model_prediction'] = ''\n",
    "\n",
    "# Label the test set using the fine-tuned model\n",
    "liar_test_df = label_data(liar_test_df, model_name=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741409195388,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 300
    },
    "id": "CiquWdf0k4n3",
    "outputId": "1f3dab09-7601-415f-d70c-217a1e9f2912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_test_df['model_prediction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1741409197070,
     "user": {
      "displayName": "Henry Zelenak",
      "userId": "01809909909045225068"
     },
     "user_tz": 300
    },
    "id": "-2-SMg7P1ii5",
    "outputId": "3f3e4f0a-0900-4563-ab14-af5f8aac9f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.60       553\n",
      "           1       0.69      0.69      0.69       714\n",
      "\n",
      "    accuracy                           0.65      1267\n",
      "   macro avg       0.65      0.65      0.65      1267\n",
      "weighted avg       0.65      0.65      0.65      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(liar_test_df['label'], liar_test_df['model_prediction']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKJ6dmqAHl2m"
   },
   "source": [
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.60      0.61      0.60       553\n",
    "           1       0.69      0.69      0.69       714\n",
    "\n",
    "    accuracy                           0.65      1267\n",
    "   macro avg       0.65      0.65      0.65      1267\n",
    "weighted avg       0.65      0.65      0.65      1267\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "izO4Q2p0mQAg"
   ],
   "provenance": [
    {
     "file_id": "1BS8ppvnMAXYKJZjuR6u2OPh3aDBdA3Mb",
     "timestamp": 1741372446020
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
