{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1743821961770,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"umwuOVbmuUG9"},"outputs":[],"source":["#%cd /content/\n","#!rm -rf fever-scorer"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1715,"status":"ok","timestamp":1743821963492,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"SWnbo9JNrNRl","outputId":"f26be7ac-f785-4bac-f6cf-423b2f15174d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'fever-scorer'...\n","remote: Enumerating objects: 224, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 224 (delta 0), reused 0 (delta 0), pack-reused 219 (from 1)\u001b[K\n","Receiving objects: 100% (224/224), 1.13 MiB | 1.93 MiB/s, done.\n","Resolving deltas: 100% (110/110), done.\n"]}],"source":["!git clone -b release-v2.0 https://github.com/sheffieldnlp/fever-scorer.git"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1743821963521,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"qhs44MknrYBW","outputId":"6331adf5-9102-4030-b595-f9c1ed561e2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/fever-scorer/fever-scorer\n"]}],"source":["%cd fever-scorer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7245,"status":"ok","timestamp":1743821970767,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"MJRmxui4s4_9","outputId":"c0d036a5-0a09-4d5a-bc6a-4fa081bdbf7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.17.0)\n"]}],"source":["!pip install -r requirements.txt\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1743821970786,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"ImTsxLYqjDs2","outputId":"02c8b504-193f-48f6-eb69-26552b825d46"},"outputs":[{"output_type":"stream","name":"stdout","text":["setup.py updated\n"]}],"source":["# Open /setup.py and add 'license=\"MIT\"' on line 12, then overwrite the file\n","import os\n","with open('setup.py', 'r') as f:\n","    lines = f.readlines()\n","    lines[11] = 'license=\"MIT\"\\n'\n","with open('setup.py', 'w') as f:\n","    f.writelines(lines)\n","    f.close()\n","    print(\"setup.py updated\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":8999,"status":"ok","timestamp":1743821979785,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"Q14RLRmVs8hd","outputId":"402eb02d-702c-4fe1-f0dc-cd0383854870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/fever-scorer/fever-scorer\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from fever-scorer==0.0.0) (1.17.0)\n","Building wheels for collected packages: fever-scorer\n","  Building wheel for fever-scorer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fever-scorer: filename=fever_scorer-0.0.0-py3-none-any.whl size=8288 sha256=4ba6e7b6e0742e5445329a53c7e4e225784dd9c0e2dfc92cdfbfa3a81ce6491b\n","  Stored in directory: /root/.cache/pip/wheels/b6/96/15/0962bf09ded2b51cf178b2b5261b279ba126ecc78d08c849de\n","Successfully built fever-scorer\n","Installing collected packages: fever-scorer\n","  Attempting uninstall: fever-scorer\n","    Found existing installation: fever-scorer 0.0.0\n","    Uninstalling fever-scorer-0.0.0:\n","      Successfully uninstalled fever-scorer-0.0.0\n","Successfully installed fever-scorer-0.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["fever"]},"id":"f9b4b58561c84ce583ed238689eb2b18"}},"metadata":{}}],"source":["!pip install ."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5070,"status":"ok","timestamp":1743821984856,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"4n9uJPKcF4hL","outputId":"b02da7a0-e74c-4ac9-b1ff-27f6c8850c1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"]}],"source":["!pip install rouge-score"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1743821985068,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"tHI9GFAlDpDV","outputId":"ee8b2165-2f9d-4a0e-fedd-5bae8ca4fefc"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}],"source":["import pandas as pd\n","import nltk  # Make sure NLTK is installed and data downloaded (e.g., nltk.download('punkt'))\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from rouge_score import rouge_scorer\n","import openai  # For LLM interaction\n","from openai import OpenAI\n","import numpy as np\n","from nltk import Tree, pos_tag, word_tokenize, ne_chunk\n","from nltk.corpus import stopwords\n","import numpy as np\n","from fever.scorer import fever_score # Import the FEVER scorer\n","from nltk import RegexpParser\n","import json\n","\n","# Download the necessary NLTK data files\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('maxent_ne_chunker_tab')\n","nltk.download('words')\n","nltk.download('stopwords')\n","nltk.download('treebank')\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1743821985088,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"hPMp1E7ivS9G","outputId":"420d7878-ee2b-4f09-b772-f30641b4e7f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Strict Score: 0.67\n","Label Accuracy: 1.00\n","Precision: 1.00\n","Recall: 0.50\n","F1 Score: 0.67\n"]}],"source":["\n","\n","# Sample instances\n","instances = [\n","    {\n","        \"label\": \"REFUTES\",\n","        \"predicted_label\": \"REFUTES\",\n","        \"predicted_evidence\": [[\"Page1\", 1], [\"Page3\", 2]],\n","        \"evidence\": [\n","            [\n","                [None, None, \"Page1\", 1],\n","                [None, None, \"Page3\", 1],\n","                [None, None, \"Page3\", 2],\n","            ],\n","        ],\n","    },\n","    {\n","        \"label\": \"SUPPORTS\",\n","        \"predicted_label\": \"SUPPORTS\",\n","        \"predicted_evidence\": [[\"Page3\", 3]],\n","        \"evidence\": [\n","            [\n","                [None, None, \"Page3\", 3]\n","            ]\n","        ],\n","    },\n","    {\n","        \"label\": \"NOT ENOUGH INFO\",\n","        \"predicted_label\": \"NOT ENOUGH INFO\",\n","        \"predicted_evidence\": [],\n","        \"evidence\": [],\n","    },\n","]\n","\n","# Calculate scores\n","strict_score, label_accuracy, precision, recall, f1 = fever_score(instances)\n","\n","# Display results\n","print(f\"Strict Score: {strict_score:.2f}\")\n","print(f\"Label Accuracy: {label_accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27474,"status":"ok","timestamp":1743822012562,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"T21Kds-sFkB5","outputId":"75e4ab7b-9ec9-4c12-97f9-08740f81e8d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount google drive\n","from google.colab import drive\n","import gc\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":905,"status":"ok","timestamp":1743822013466,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"-Op1htlxFQZz"},"outputs":[],"source":["from google.colab import userdata\n","api_key = userdata.get('openaikey')\n","client = OpenAI(api_key=api_key)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1743822079535,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"HrnHrCbCFXXs","outputId":"71d432f5-9a3e-42aa-80e3-8fea3fe39aaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/SUNY_Poly_DSA598\n"]}],"source":["%cd ../drive/My Drive/SUNY_Poly_DSA598/"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1743822081700,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"MWAcKxBFFcfQ","outputId":"f3540fa0-a13f-4c5b-d9e7-7f0f7ddfacd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["archive\t\t\t  .git\t\t\t\t  presentation\n","datasets\t\t  .gitignore\t\t\t  transcribe_voice_notes.ipynb\n","FEVER_set_creation.ipynb  liar_gpt4omini_base_eval.ipynb  work_documents\n","FEVER_set_update.ipynb\t  Module_2_dev.ipynb\n"]}],"source":["!ls -a"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1743822082431,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"oZ5Hhk7HUAld","outputId":"57a5faa9-cdb1-4a7a-f4fa-b93347c5f2e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/SUNY_Poly_DSA598/datasets/FEVER\n"]}],"source":["%cd ./datasets/FEVER/"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1743822083720,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"TxfUDQuvUDew","outputId":"f2a9acf8-8c88-4a43-8c96-9ed1667f9559"},"outputs":[{"output_type":"stream","name":"stdout","text":["AVeriTeC   fever2-adversarial.jsonl\t    fever-train.jsonl  paper_dev.jsonl\t tabular_sets\n",".DS_Store  feverous_train_challenges.jsonl  GPT_sets\t       paper_test.jsonl  wiki-pages\n"]}],"source":["!ls -a"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1743822086815,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"IBL_wR71bbeh"},"outputs":[],"source":["def load_jsonl(file_path, encoding='utf-8'):\n","    \"\"\"Loads a JSON Lines file into a list of Python objects.\"\"\"\n","    data = []\n","    with open(file_path, 'r', encoding=encoding) as f:  # Specify encoding for safety\n","        for line in f:\n","            data.append(json.loads(line))  # Parse each line individually\n","    return data"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2615,"status":"ok","timestamp":1743822090539,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"fxxK5zjBPXar"},"outputs":[],"source":["# Data paths (replace with your actual paths if different)\n","fever_path = \"./datasets/FEVER/\"\n","train_clf_path = f\"tabular_sets/tabular_clf_paper_dev_train/v1_segmented_sentIDs_n3461_04-04_002.csv\"\n","valid_clf_path = f\"tabular_sets/tabular_clf_paper_dev_valid/v1_segmented_sentIDs_n1482_04-04_002.csv\"\n","train_sentEx_path = f\"tabular_sets/tabular_sentEx_paper_dev_train/v1_segmented_sentIDs_n3461_04-04_002.csv\"\n","valid_sentEx_path = f\"tabular_sets/tabular_sentEx_paper_dev_valid/v1_segmented_sentIDs_n1482_04-04_002.csv\"\n","test_path = f\"paper_test.jsonl\"\n","train_path = f\"paper_dev.jsonl\"\n","\n","# Load datasets\n","#train_clf = pd.read_csv(train_clf_path)\n","#valid_clf = pd.read_csv(valid_clf_path)\n","train_sentEx = pd.read_csv(train_sentEx_path)\n","valid_sentEx = pd.read_csv(valid_sentEx_path)\n","test_jsonl = load_jsonl(test_path)\n","train_jsonl = load_jsonl(train_path)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1743822094690,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"FwlHIP2GEmz7","outputId":"e35f1e25-4299-4e73-8862-4d5427ca55d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train set label distribution:\n","label\n","SUPPORTS           1156\n","REFUTES            1156\n","NOT ENOUGH INFO    1149\n","Name: count, dtype: int64\n","Valid set label distribution:\n","label\n","SUPPORTS           495\n","REFUTES            495\n","NOT ENOUGH INFO    488\n","Name: count, dtype: int64\n","Train set label distribution after balancing:\n","label\n","NOT ENOUGH INFO    1149\n","REFUTES            1149\n","SUPPORTS           1149\n","Name: count, dtype: int64\n","Valid set label distribution after balancing:\n","label\n","NOT ENOUGH INFO    488\n","REFUTES            488\n","SUPPORTS           488\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-36-03091368d446>:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  train_sentEx = train_sentEx.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n","<ipython-input-36-03091368d446>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  valid_sentEx = valid_sentEx.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n"]}],"source":["# Show the distribution of labels\n","print(f\"Train set label distribution:\")\n","print(train_sentEx['label'].value_counts())\n","print(f\"Valid set label distribution:\")\n","print(valid_sentEx['label'].value_counts())\n","\n","# Balance the labels by reducing each to the minimum count\n","min_count = min(train_sentEx['label'].value_counts())\n","train_sentEx = train_sentEx.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n","min_count = min(valid_sentEx['label'].value_counts())\n","valid_sentEx = valid_sentEx.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n","\n","print(f\"Train set label distribution after balancing:\")\n","print(train_sentEx['label'].value_counts())\n","print(f\"Valid set label distribution after balancing:\")\n","print(valid_sentEx['label'].value_counts())"]},{"cell_type":"markdown","source":["## Module 2"],"metadata":{"id":"iTBcIxD_LoXs"}},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1743827131095,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"TO5Dt_5vCGqG"},"outputs":[],"source":["def module_2_semi_supervised_distillation(claim, documents, entities, keywords, sim_thresh=0.2, verbose=0, debug=False):\n","    \"\"\"\n","    Module 2: Semi-supervised Distillation for sentence extraction.\n","\n","    Args:\n","        claim (str): The input claim.\n","        documents (list of str): List of retrieved documents (full text).\n","        entity (str):  The main entity in the claim (or None if not found).\n","        keywords (list of str):  Top keywords from the claim.\n","\n","    Returns:\n","        tuple: (list of str, str):  A list of extracted evidence sentences and the exit status (\"NOT ENOUGH INFO\" or \"OK\").\n","    \"\"\"\n","\n","\n","    extracted_sentences = []\n","    max_iterations = min(5, len(documents)) # This will be determined later with actual number of sentences across all docs\n","    if debug:\n","      print(f\"DEBUG 2.1.1:\")\n","      print(f\"\\tNumber of documents: {len(documents)}\")\n","      print(f\"\\tMax iterations: {max_iterations}\")\n","      print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","    \"\"\"\n","    if entities == []:\n","      if verbose == 1:\n","        print(\"No entities found, early exiting...\")\n","        return [], \"NOT ENOUGH INFO\" # Early exit if no entity\n","    \"\"\"\n","\n","    # convert entities to string\n","    if not entities:\n","      entities = \"\"\n","      # prompts\n","      prompts = {\n","            \"init\": f\"Retrieve sentences from the list that either support or refute the following claim. Specifically, focus on sentences mentioning {keywords}. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\",\n","            \"followup\": f\"You didn’t find enough sentences. Find additional (new) sentences that are relevant to key points in the claim. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\",\n","        }\n","    else:\n","      entities = \", \".join(entities)\n","      # prompts\n","      prompts = {\n","            \"init\": f\"Retrieve sentences from the list that either support or refute the following claim. Specifically, focus on sentences mentioning {entities} or {keywords}. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\",\n","            \"followup\": f\"You didn’t find enough sentences. Find additional (new) sentences that that are relevant to key points in the claim. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\",\n","      }\n","      if debug:\n","        print(f\"DEBUG 2.1.2:\")\n","        print(f\"\\tClaim: {claim}\")\n","        print(f\"\\tEntities: {entities}\")\n","        print(f\"\\tKeywords: {keywords}\")\n","        print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","    for iteration in range(max_iterations):\n","      # 2.2 Prompt Selection (no agent - programmatic)\n","      if iteration == 0:\n","          prompt = prompts[\"init\"]\n","      else:\n","          prompt = prompts[\"followup\"]\n","\n","\n","      # 2.3 Sentence Extraction (with pre-filtering)\n","      # Drop empty sentences from the list\n","      documents = [doc for doc in documents if doc.strip()]\n","      #filtered_text = sliding_window_filter(documents, entities, keywords)\n","      # Simply form the list of document strings into one string joined by \\n for now\n","      filtered_text = \"\\n\".join(documents)\n","      if debug:\n","        print(f\"DEBUG 2.3.1:\")\n","        print(f\"\\tFiltered text: {filtered_text}\")\n","        print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","      new_sentences = extract_sentences_with_llm(claim, filtered_text, prompt, debug)\n","\n","      if debug:\n","        print(f\"DEBUG 2.3.3:\")\n","        print(f\"\\tNumber of retrieved sentences on iteration {iteration}: {len(new_sentences)}\")\n","        print(f\"\\tNew sentences: {new_sentences}\")\n","        print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","      if new_sentences != [\"NOT ENOUGH INFO\"]:  # LLM found no relevant sentences\n","        if verbose == 1:\n","          print(f\"2.3: LLM found sentences on iteration {iteration}.\")\n","\n","        # 2.4 Similarity Comparison and Thresholding\n","        new_sentences = similarity_thresholding(claim, new_sentences, sim_thresh, True)\n","\n","        if verbose == 1:\n","          print(f\"\\tExtracted sentences: {new_sentences}\")\n","          print(f\"\\tNumber of extracted sentences: {len(new_sentences)}\")\n","          print(f\"\\tMax iterations: {max_iterations}\")\n","          print(\"-------------------------------------------------------------\")\n","\n","        extracted_sentences.extend(new_sentences)  # Add new sentences to the list\n","\n","        if debug:\n","          print(f\"DEBUG 2.4.2:\")\n","          print(f\"\\tAdded {len(new_sentences)} new sentences on iteration {iteration}.\")\n","          print(f\"\\tTotal extracted sentences: {len(extracted_sentences)}\")\n","          print(f\"\\tExtracted sentences: {extracted_sentences}\")\n","          print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","          print(f\"Reached the end of the loop, iteration: {iteration}\")\n","          print(\"#-------------------------------------------------------------#\")\n","        if len(extracted_sentences) >= min(max_iterations, 5):\n","            if verbose == 1:\n","                print(f\"2.4: Found enough sentences, exiting...\")\n","                print(\"-------------------------------------------------------------\")\n","            return extracted_sentences, \"OK\"\n","\n","        #Check for final early exit\n","        elif len(extracted_sentences) < min(max_iterations, 5) and iteration == max_iterations: # Pilot study will determine best practices here\n","          if verbose == 1:\n","            print(f\"2.4: REACHED MAX ITERATIONS, BUT FEWER THAN THE MAXIMUM POSSIBLE SENTENCES FOUND, EARLY EXITING WITH WHATEVER WE HAVE SO FAR\")\n","            print(\"-------------------------------------------------------------\")\n","          return extracted_sentences, \"OK\"\n","      else:\n","        if iteration == 0:  # No sentences found in the first iteration\n","          if iteration+1 != max_iterations:\n","            if verbose == 1:\n","              print(f\"2.3: LLM claims to find NOT ENOUGH INFO on first iteration (focusing on entities), reprompting without entities...\")\n","              print(\"-------------------------------------------------------------\")\n","            continue\n","          else:\n","            if verbose == 1:\n","              print(f\"2.3: LLM claims to find NOT ENOUGH INFO on first iteration and ONLY 1 ITERATION POSSIBLE, EARLY EXITING...\")\n","              print(\"-------------------------------------------------------------\")\n","            return [], \"NOT ENOUGH INFO\"  # Early exit if no relevant sentences in first pass.\n","        elif iteration == 1 and len(extracted_sentences) != 0:  # No sentences found in the second iteration, but at least one found in the first iteration\n","          if verbose == 1:\n","            print(f\"2.3: LLM found no relevant sentences in the second iteration, but found at least one in the first iteration. Exiting with what we have...\")\n","            print(\"-------------------------------------------------------------\")\n","          return extracted_sentences, \"OK\"\n","        elif iteration == 1 and len(extracted_sentences) == 0:  # No sentences found in the second iteration and no sentences found in the first iteration\n","          if verbose == 1:\n","            print(f\"2.3: LLM found no relevant sentences in the second iteration and no sentences found in the first iteration, early exiting...\")\n","            print(\"-------------------------------------------------------------\")\n","          return [], \"NOT ENOUGH INFO\"\n","        else:\n","          if verbose == 1:\n","            print(f\"2.3: LLM claims to find NOT ENOUGH INFO after 2 iterations, early exiting...\")\n","            print(\"-------------------------------------------------------------\")\n","          return [], \"NOT ENOUGH INFO\"  # Early exit if no relevant sentences in third pass.\n","\n","\n","def sliding_window_filter(documents, entity, keywords, debug=False):\n","    \"\"\"\n","    Performs sliding window filtering based on entity and keywords.\n","\n","    Args:\n","        documents (list of str):  List of documents.\n","        entity (str): The entity to match.\n","        keywords (list of str): The keywords to match.\n","\n","    Returns:\n","        str: Concatenated filtered text.\n","    \"\"\"\n","    # TODO: Implement sliding window filtering logic (using NLTK, spaCy, etc.).\n","    # This function should concatenate sentences from windows that contain entity/keywords.\n","    filtered_sentences = []\n","\n","    for document in documents:\n","        sentences = nltk.sent_tokenize(document)\n","        window_size = 3  # Experiment with different window sizes.\n","        for i in range(len(sentences) - window_size + 1):\n","            window = sentences[i : i + window_size]\n","            window_text = \" \".join(window)\n","            if entity in window_text and any(keyword in window_text for keyword in keywords):\n","                filtered_sentences.extend(window) # Add matching sentences from window to filtered sentences\n","\n","    filtered_text = \"\\n\".join(filtered_sentences)\n","    return filtered_text\n","\n","def extract_sentences_with_llm(claim, filtered_text, prompt, debug=False):\n","    \"\"\"\n","    Extracts sentences using an LLM.\n","\n","    Args:\n","        claim (str): The input claim.\n","        filtered_text (str): The pre-filtered text.\n","        prompt (str): The prompt for the LLM.\n","\n","    Returns:\n","        list of str: Extracted sentences.\n","    \"\"\"\n","    # TODO: Implement LLM interaction (using OpenAI API, etc.).\n","    # Use the provided prompt and filtered_text to extract sentences with the LLM.\n","\n","    if debug:\n","      print(f\"DEBUG 2.3.2:\")\n","      print(f\"\\tPrompt: {prompt}\")\n","      print(f\"\\tFiltered text: {filtered_text}\")\n","      print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini-2024-07-18\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts evidence sentences.\"},\n","            {\"role\": \"user\", \"content\": f\"{prompt}\\nClaim: {claim}\\nText: {filtered_text}\"},\n","        ],\n","        max_tokens=1024,\n","        n=1,\n","        stop=None,  # Or a suitable stop sequence\n","        temperature=0.9,  # Adjust as needed\n","    )\n","    extracted_sentences_raw = response.choices[0].message.content\n","    extracted_sentences = extracted_sentences_raw.split('\\n')  # Assuming sentences are separated by newlines\n","\n","    return extracted_sentences\n","\n","\n","def similarity_thresholding(claim, sentences, threshold=0.0, debug=False):\n","    \"\"\"\n","    Thresholds sentences based on similarity to the claim.\n","\n","    Args:\n","        claim (str): The input claim.\n","        sentences (list of str): The sentences to threshold.\n","\n","    Returns:\n","        list of str:  The sentences that meet the similarity threshold.\n","    \"\"\"\n","    # TODO: Implement similarity calculations (ROUGE, TF-IDF, cosine similarity).\n","    # Return only the sentences that exceed the defined threshold(s).\n","\n","    filtered_sentences = []\n","\n","    vectorizer = TfidfVectorizer()  # Initialize TF-IDF vectorizer\n","    claim_tfidf = vectorizer.fit_transform([claim])\n","    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n","\n","    for sentence in sentences:\n","        sentence_tfidf = vectorizer.transform([sentence])\n","        cosine_sim = cosine_similarity(claim_tfidf, sentence_tfidf)[0][0]\n","        rouge_scores = scorer.score(claim, sentence)\n","        rouge1_score = rouge_scores['rouge1'].fmeasure  # Example: Use ROUGE-1 F1-score\n","\n","        if debug:\n","          print(f\"DEBUG 2.4.1:\")\n","          print(f\"\\tClaim: {claim}\")\n","          print(f\"\\tSentence: {sentence}\")\n","          print(f\"\\tCosine Similarity: {cosine_sim}\")\n","\n","        if cosine_sim >= threshold and rouge1_score >= threshold:  # Example: Combine cosine similarity and ROUGE\n","            filtered_sentences.append(sentence)\n","            if debug:\n","              print(f\"\\tAdded sentence to filtered sentences: {sentence}\")\n","              print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","        else:\n","          if debug:\n","            print(f\"\\tSentence did not meet similarity threshold: {sentence}\")\n","            print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","    return filtered_sentences\n","\n","\n","# Entity and keywords extraction function\n","def extract_entities(text):\n","    \"\"\"\n","    Extracts entities from the text using NLTK's Named Entity Chunker.\n","\n","    Args:\n","        text (str): The input text.\n","\n","    Returns:\n","        list of str: List of extracted entities.\n","    \"\"\"\n","    stop_words = set(stopwords.words('english'))\n","    tokens = word_tokenize(text)\n","    tokens = [word for word in tokens if word.lower() not in stop_words]\n","    tagged_tokens = pos_tag(tokens)\n","    named_entities = ne_chunk(tagged_tokens)\n","\n","    entities = []\n","    for subtree in named_entities:\n","        if isinstance(subtree, Tree):\n","            entity = \" \".join([word for word, tag in subtree.leaves()])\n","            entities.append(entity)\n","\n","    return entities\n","\n","\n","# Keyword extraction function\n","def extract_keywords(text):\n","    \"\"\"\n","    Extracts keywords from the text using TF-IDF.\n","\n","    Args:\n","        text (str): The input text.\n","\n","    Returns:\n","        list of str: List of extracted keywords.\n","    \"\"\"\n","    vectorizer = TfidfVectorizer(stop_words='english', max_features=10)  # Adjust max_features as needed\n","    tfidf_matrix = vectorizer.fit_transform([text])\n","    feature_names = vectorizer.get_feature_names_out()\n","    dense = tfidf_matrix.todense()\n","    denselist = dense.tolist()\n","    # Convert the list to a NumPy array to use argsort()\n","\n","    dense_array = np.array(denselist[0])\n","    keywords = [feature_names[i] for i in dense_array.argsort()[-5:]]  # Get top 5 keywords\n","\n","    return keywords"]},{"cell_type":"markdown","metadata":{"id":"qz3SVu5uhcxx"},"source":["## Module 1"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1743824835128,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"bK5axsjBn_Fw"},"outputs":[],"source":["# Module 1: Document retrieval from wikipedia based on keywords, entities, and claim\n","import requests\n","from bs4 import BeautifulSoup\n","import re\n","import ast\n","\n","\n","def query_generator(claim, keywords, entities, debug=False):\n","    \"\"\"\n","    Generates a query for Wikipedia based on the claim, keywords, and entities.\n","\n","    Args:\n","        claim (str): The input claim.\n","        keywords (list of str): The keywords to include in the query.\n","        entities (list of str): The entities to include in the query.\n","\n","    Returns:\n","        str: The generated query.\n","    \"\"\"\n","    prompt = f\"Generate a Wikipedia query based on the claim: '{claim}'. Include keywords: {', '.join(keywords)} and entities: {', '.join(entities)}. Respond only with the query as a string on a single line.\"\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini-2024-07-18\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates Wikipedia queries.\"},\n","            {\"role\": \"user\", \"content\": prompt},\n","        ],\n","        max_tokens=512,  # Adjust as needed\n","        n=1,\n","        stop=None,  # Or a suitable stop sequence\n","        temperature=0.9,  # Adjust as needed\n","    )\n","    query = response.choices[0].message.content\n","    return query\n","\n","def retrieve_documents_from_wikipedia(claim, keywords, entities, debug=False):\n","    \"\"\"\n","    Retrieves documents from Wikipedia based on the claim, keywords, and entities.\n","\n","    Args:\n","        claim (str): The input claim.\n","        keywords (list of str): The keywords to include in the query.\n","        entities (list of str): The entities to include in the query.\n","\n","    Returns:\n","        list of str: Retrieved documents.\n","    \"\"\"\n","    query = query_generator(claim, keywords, entities, debug=False)\n","    if debug:\n","      print(f\"DEBUG 1.2.1:\")\n","      print(f\"\\tQuery: {query}\")\n","      print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","    # Perform a Wikipedia search\n","    search_url = f\"https://en.wikipedia.org/w/index.php?search={requests.utils.quote(query)}\"\n","    response = requests.get(search_url)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    # Extract links to Wikipedia pages\n","    links = soup.find_all('a', href=re.compile(r'^/wiki/'))\n","    documents = []\n","    # Get just the introduction of each page\n","    for link in links:\n","        page_url = f\"https://en.wikipedia.org{link['href']}\"\n","        response = requests.get(page_url)\n","        data = response.json\n","        if 'parse' in data:\n","          page_content = data['parse']['text']['*']\n","          # Extract the introduction section (the first paragraph element)\n","          intro_section = re.search(r'<p>(.*?)</p>', page_content, re.DOTALL)\n","          if intro_section:\n","            intro_text = intro_section.group(1) # Get the text inside the first <p> tag\n","            # Remove HTML tags\n","            intro_text = re.sub(r'<.*?>', '', intro_text)\n","            # Remove references\n","            intro_text = re.sub(r'\\[.*?\\]', '', intro_text)\n","            # Remove digits that are preceded by any letter, period, colon, semicolon, endash (–), and emdash(—) and followed by a space\n","            intro_text = re.sub(r'(?<=[a-zA-Z0-9\\.\\:\\;\\–\\—])\\d+(?=\\s)', '', intro_text)\n","            # Convert encoded html entities to unicode (e.g., &amp; to &)\n","            intro_text = re.sub(r'&[a-zA-Z0-9#]+;', '', intro_text)\n","            # Remove extra whitespace\n","            intro_text = re.sub(r'\\s+', ' ', intro_text).strip()\n","            documents.append(intro_text)\n","        else:\n","            print(f\"Error: No parse data found for {page_url}\")\n","    if debug:\n","      print(f\"DEBUG 1.2.2:\")\n","      print(f\"\\tNumber of documents retrieved: {len(documents)}\")\n","      print(\"-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","    return documents\n","\n","index = 0\n","def get_test_claim(df, mode, verbose=0, debug=False):\n","    \"\"\"\n","    In \"test\" mode, gets data for a claim by matching a row in the df (which contains the claim and the wikipedia text data) to the JSONL object\n","    (which contains the claim and the evidence references) by the claim, returning the claim, label, evidence sentences, documents, and evidence references.\n","\n","    In 'live' mode, gets data for a claim by generating a query and retrieving documents from Wikipedia. THIS MODE IS NOT COMPATIBLE WITH FEVER SCORING.\n","\n","    EXAMPLE:\n","    {\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, null, null]]]}\n","    {\"id\": 163803, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"Ukrainian Soviet Socialist Republic was a founding participant of the UN.\", \"evidence\": [[[296950, 288668, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[298602, 290067, \"Ukrainian_Soviet_Socialist_Republic\", 7], [298602, 290067, \"United_Nations\", 0]], [[300696, 291816, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344347, 327887, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344994, 328433, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344997, 328435, \"Ukrainian_Soviet_Socialist_Republic\", 7]]]}\n","    {\"id\": 70041, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"2 Hearts is a musical composition by Minogue.\", \"evidence\": [[[225394, 230056, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[317953, 306972, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[319638, 308345, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[319643, 308348, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]]]}\n","    {\"id\": 202314, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"The New Jersey Turnpike has zero shoulders.\", \"evidence\": [[[238335, 240393, \"New_Jersey_Turnpike\", 15]]]}\n","    \"\"\"\n","\n","\n","    global index\n","    claim = df.iloc[index]['claim']\n","    documents = df.iloc[index]['full_text']\n","    documents = documents.split('\\n')\n","    label = df.iloc[index]['label']\n","    keywords = extract_keywords(claim)  # Extract keywords from the claim\n","    evidence_items = df.iloc[index]['evidence_sentences']\n","\n","    if debug:\n","      print(f\"DEBUG 1.1.1:\")\n","      print(f\"Evidence items: {evidence_items}\")\n","    # Evidence items are in the format (sentence, page_title, sentence_id, entities[entity1, entity2, ...])\n","    '''\n","    [('Despite their San Francisco Bay Area origins , they played in a Southern rock style , with lyrics about bayous , catfish , the Mississippi River , and other popular elements of Southern United States iconography , as well as political and socially-conscious lyrics about topics including the Vietnam War .', 'Creedence_Clearwater_Revival', 3, ['Vietnam War', 'Southern rock', 'San Francisco Bay Area', 'Opposition to United States involvement in the Vietnam War', 'rock', 'Mississippi River', 'rock music']), ('Creedence Clearwater Revival , often informally abbreviated to Creedence or CCR , was an American rock band active in the late 1960s and early 1970s .', 'Creedence_Clearwater_Revival', 0, ['rock', 'rock music']), ('Their musical style encompassed the roots rock , swamp rock , and blues rock genres .', 'Creedence_Clearwater_Revival', 2, ['roots rock', 'rock', 'blues rock', 'rock music', 'swamp rock'])]\n","    '''\n","    index += 1\n","    # Return essential information (we only need the documents, keywords, entities, claim, and label for the NOT ENOUGH INFO case, since we don't need to extract evidence sentences)\n","    if label == \"NOT ENOUGH INFO\":\n","        evidence_items = []\n","        entities = extract_entities(claim)  # Extract entities from the claim\n","        if verbose == 1:\n","          print(f\"-------------------------------------------------------------\")\n","          print(f\"In get_test_claim, running in {mode} mode...\")\n","          print(f\"Claim: {claim}\")\n","          print(f\"Label: {label}\")\n","          print(f\"Evidence items: {evidence_items}\")\n","          print(f\"Documents: {documents}\")\n","          print(f\"Entities: {entities}\")\n","          print(f\"Keywords: {keywords}\")\n","          print(f\"-------------------------------------------------------------\")\n","        return claim, label, evidence_items, documents, keywords, entities\n","\n","    entities = []\n","    # Use ast.literal_eval to convert the string representation of the list to an actual list\n","    evidence_items = ast.literal_eval(evidence_items)\n","    # Extract entities from the evidence items\n","    for item in evidence_items:\n","        entities.extend(item[3])\n","        if debug:\n","          print(f\"DEBUG 1.1.2:\")\n","          print(f\"\\tEvidence item: {item}\")\n","          print(f\"\\tEntities: {item[3]}\")\n","          print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","    # Remove duplicates\n","    entities = list(set(entities))\n","    # Remove empty strings\n","    entities = [entity for entity in entities if entity]\n","\n","    if verbose == 1:\n","        print(f\"-------------------------------------------------------------\")\n","        print(f\"In get_test_claim, running in {mode} mode...\")\n","        print(f\"Claim: {claim}\")\n","        print(f\"Label: {label}\")\n","        print(f\"Evidence items: {evidence_items}\")\n","        print(f\"Documents: {documents}\")\n","        print(f\"Entities: {entities}\")\n","        print(f\"Keywords: {keywords}\")\n","        print(f\"-------------------------------------------------------------\")\n","\n","\n","    return claim, label, evidence_items, documents, keywords, entities\n","\n"]},{"cell_type":"code","source":["'''\n","For eventual \"live\" testing of the system:\n","\n","    if mode == 'live':\n","        # Generate a query and retrieve documents from Wikipedia\n","        documents = retrieve_documents_from_wikipedia(claim, keywords, entities, debug=debug)\n","        if debug:\n","          print(f\"DEBUG 1.2.3, Live mode:\")\n","          print(f\"\\tDocuments: {documents}\")\n","          print(\"-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","\n","    elif mode == 'test':\n","        # Use the documents from the df\n","        if debug:\n","          print(f\"DEBUG 1.2.4, Test mode:\")\n","          print(f\"\\tDocuments: {documents}\")\n","          print(\"-_-_-_-_-_-_-_-_-_-_-_-_-\")\n","'''"],"metadata":{"id":"k0pPVf11MFNX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1743823780228,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"C-2nuV15vpuQ"},"outputs":[],"source":["# Shuffle the valid_sentEx df\n","#valid_sentEx = valid_sentEx.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1245,"status":"ok","timestamp":1743826646290,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"},"user_tz":240},"id":"FJ6Azxe8MHBB","outputId":"c516456a-74fe-45ef-d3b9-a1086c2fd9dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG 1.1.1:\n","Evidence items: [[\"As of 2005 , the town 's population is 283 .\", 'Angelsberg', 1, []], ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .', 'Angelsberg', 0, ['Fischbach, Mersch', 'commune', 'Fischbach', 'Luxembourg', 'Communes of Luxembourg']]]\n","DEBUG 1.1.2:\n","\tEvidence item: [\"As of 2005 , the town 's population is 283 .\", 'Angelsberg', 1, []]\n","\tEntities: []\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 1.1.2:\n","\tEvidence item: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .', 'Angelsberg', 0, ['Fischbach, Mersch', 'commune', 'Fischbach', 'Luxembourg', 'Communes of Luxembourg']]\n","\tEntities: ['Fischbach, Mersch', 'commune', 'Fischbach', 'Luxembourg', 'Communes of Luxembourg']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","-------------------------------------------------------------\n","In get_test_claim, running in test mode...\n","Claim: Angelsberg is a place.\n","Label: SUPPORTS\n","Evidence items: [[\"As of 2005 , the town 's population is 283 .\", 'Angelsberg', 1, []], ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .', 'Angelsberg', 0, ['Fischbach, Mersch', 'commune', 'Fischbach', 'Luxembourg', 'Communes of Luxembourg']]]\n","Documents: ['', \"Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \"]\n","Entities: ['Communes of Luxembourg', 'Luxembourg', 'commune', 'Fischbach', 'Fischbach, Mersch']\n","Keywords: ['angelsberg', 'place']\n","-------------------------------------------------------------\n","DEBUG 1.2.4, Test mode:\n","\tDocuments: ['', \"Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \"]\n","-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.1.1:\n","\tNumber of documents: 2\n","\tMax iterations: 2\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.1.2:\n","\tClaim: Angelsberg is a place.\n","\tEntities: Communes of Luxembourg, Luxembourg, commune, Fischbach, Fischbach, Mersch\n","\tKeywords: ['angelsberg', 'place']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.3.1:\n","\tFiltered text: \n","Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.3.2:\n","\tPrompt: Retrieve sentences from the list that either support or refute the following claim. Specifically, focus on sentences mentioning Communes of Luxembourg, Luxembourg, commune, Fischbach, Fischbach, Mersch or ['angelsberg', 'place']. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\n","\tFiltered text: \n","Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.3.3:\n","\tNumber of retrieved sentences on iteration 0: 1\n","\tNew sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","2.3: LLM found sentences on iteration 0.\n","DEBUG 2.4.1:\n","\tClaim: Angelsberg is a place.\n","\tSentence: Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .\n","\tCosine Similarity: 0.8164965809277261\n","\tAdded sentence to filtered sentences: Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","\tExtracted sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","\tNumber of extracted sentences: 1\n","\tMax iterations: 2\n","-------------------------------------------------------------\n","DEBUG 2.4.2:\n","\tAdded 1 new sentences on iteration 0.\n","\tTotal extracted sentences: 1\n","\tExtracted sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","Reached the end of the loop, iteration: 0\n","#-------------------------------------------------------------#\n","DEBUG 2.3.1:\n","\tFiltered text: \n","Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.3.2:\n","\tPrompt: You didn’t find enough sentences. Find additional (new) sentences that that are relevant to key points in the claim. Order the sentences by relevance, highest first, and return a list separated by the return character. If there are no relevant sentences, respond with 'NOT ENOUGH INFO'. DO NOT CREATE ANY SENTENCES THAT ARE NOT IN THE PROVIDED LIST, AND DO NOT TRUNCATE THE SENTENCE.\n","\tFiltered text: \n","Angelsberg is a small town in the commune of Fischbach , in central Luxembourg . As of 2005 , the town 's population is 283 . \n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","DEBUG 2.3.3:\n","\tNumber of retrieved sentences on iteration 1: 1\n","\tNew sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","2.3: LLM found sentences on iteration 1.\n","DEBUG 2.4.1:\n","\tClaim: Angelsberg is a place.\n","\tSentence: Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .\n","\tCosine Similarity: 0.8164965809277261\n","\tAdded sentence to filtered sentences: Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","\tExtracted sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","\tNumber of extracted sentences: 1\n","\tMax iterations: 2\n","-------------------------------------------------------------\n","DEBUG 2.4.2:\n","\tAdded 1 new sentences on iteration 1.\n","\tTotal extracted sentences: 2\n","\tExtracted sentences: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .', 'Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n","Reached the end of the loop, iteration: 1\n","#-------------------------------------------------------------#\n","2.4: Found enough sentences, exiting...\n","-------------------------------------------------------------\n","Extracted evidence: ['Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .', 'Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .']\n","Status: OK\n","Comparing 'Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .' with 'As of 2005 , the town 's population is 283 .'\n","\tat 0.8Similarity = False\n","Comparing 'Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .' with 'Angelsberg is a small town in the commune of Fischbach , in central Luxembourg .'\n","\tat 0.8Similarity = True\n","Evidence item matches extracted evidence.\n","Gold evidence: [[None, None, 'Angelsberg', 1], [None, None, 'Angelsberg', 0]]\n","Predicted evidence: [['Angelsberg', 0]]\n"]}],"source":["#claim, documents_text, label = generate_claim_tab_data(valid_sentEx)  # Generate a claim and its associated documents for tabular data\n","verbose = 1\n","claim, label, evidence_items, documents_text, keywords, entities = get_test_claim(valid_sentEx, mode='test', verbose=1, debug=True)\n","\n","# Convert documents to list of strings if it's a single string\n","if isinstance(documents_text, str):\n","    documents = documents_text.split('\\n')\n","elif isinstance(documents_text, list):\n","  documents = documents_text\n","else:\n","  raise Exception(f\"documents must be a list of strings, not {type(documents_text)}\")\n","\n","sim_thresh = 0.1\n","extracted_evidence, status = module_2_semi_supervised_distillation(claim, documents, entities, keywords, sim_thresh, verbose=1, debug=True)\n","\n","print(f\"Extracted evidence: {extracted_evidence}\")\n","print(f\"Status: {status}\")\n","\n","# Quick near-match function\n","def near_match(a, b, threshold=0.8, verbose=0):\n","  \"\"\"\n","  Checks if two strings are similar based on a threshold.\n","\n","  Args:\n","      a (str): The first string.\n","      b (str): The second string.\n","      threshold (float): The similarity threshold.\n","\n","  Returns:\n","      bool: True if the strings are similar, False otherwise.\n","  \"\"\"\n","  sim = len(set(a.split()).intersection(set(b.split()))) / max(len(a.split()), len(b.split())) >= threshold\n","  if verbose == 1:\n","      print(f\"Comparing '{a}' with '{b}'\\n\\tat {threshold}Similarity = {sim}\")\n","  return sim\n","\n","# Match the evidence references with the extracted evidence\n","gold_evidence = []\n","for item in evidence_items:\n","    gold_evidence.append([None, None, item[1], item[2]])\n","predicted_evidence = []\n","extracted_evidence = list(set(extracted_evidence))\n","if status == \"OK\":\n","  # Check if the extracted evidence is not empty\n","  if extracted_evidence:\n","    # Iterate through the extracted evidence and evidence items\n","    for sentence in extracted_evidence:\n","        for item in evidence_items:\n","            if near_match(sentence, item[0], threshold=0.8, verbose=1):\n","                predicted_evidence.append([item[1], item[2]])\n","                if verbose == 1:\n","                    print(f\"Evidence item matches extracted evidence.\")\n","                break\n","            else:\n","                #if verbose == 1:\n","                    #print(f\"Evidence item '{item[0]}' does not match extracted evidence '{sentence}'\")\n","                continue\n","  else:\n","    print(f\"No extracted evidence found, despite status OK.\")\n","else:\n","  print(f\"Status is NOT ENOUGH INFO, no evidence references found.\")\n","  predicted_evidence = []\n","\n","if verbose == 1:\n","    print(f\"Gold evidence: {gold_evidence}\")\n","    print(f\"Predicted evidence: {predicted_evidence}\")"]},{"cell_type":"code","source":["# Build the object for FEVER scoring\n","\n","# If label is not NOT ENOUGH INFO, coin flip whether label is SUPPORTS or REFUTES for clear testing of module 2 (This is module 3 for now)\n","if status != \"NOT ENOUGH INFO\":\n","    if np.random.rand() < 0.5:\n","        predicted_label = \"SUPPORTS\"\n","    else:\n","        predicted_label = \"REFUTES\"\n","else:\n","    predicted_label = \"NOT ENOUGH INFO\"\n","pred_evdc = [['Angelsberg', 0], ['Angelsberg', 1]]\n","\n","instances = [\n","    {\n","        \"label\": label,\n","        \"predicted_label\": predicted_label,\n","        \"predicted_evidence\": predicted_evidence,\n","        \"evidence\": [\n","            gold_evidence\n","        ],\n","    },\n","]\n","\n","strict_score, label_accuracy, precision, recall, f1 = fever_score(instances)\n","fever_results = {\n","    'strict_score': strict_score,\n","    'label_accuracy': label_accuracy,\n","    'precision': precision,\n","    'recall': recall,\n","    'f1': f1\n","}\n","\n","print(\"Predicted label: \" + predicted_label)\n","for key, value in fever_results.items():\n","    print(f\"{key}\\t{value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPhhEDnUHkbC","executionInfo":{"status":"ok","timestamp":1743826816527,"user_tz":240,"elapsed":9,"user":{"displayName":"Henry Zelenak","userId":"01809909909045225068"}},"outputId":"b30187b3-07fd-484e-a835-8a6571600e3e"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted label: REFUTES\n","strict_score\t0.0\n","label_accuracy\t0.0\n","precision\t1.0\n","recall\t0.0\n","f1\t0.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7_3Fpx4hcxy"},"outputs":[],"source":["\n","\n","# Convert extracted evidence to FEVER format\n","predicted_evidence = []\n","for sentence in extracted_evidence:\n","    for doc in documents:\n","        if sentence in doc:  # or a more robust check if sentences are preprocessed\n","            line_num = doc.split('\\n').index(sentence)  # Assumes sentences are split by newlines in doc\n","            predicted_evidence.append([f\"page_{documents.index(doc)}\", line_num])\n","            break  # Stop searching once sentence is found in a document\n","\n","# Construct FEVER prediction instance\n","prediction_instance = {\n","    \"predicted_label\": \"SUPPORTS\" if status == \"OK\" else \"NOT ENOUGH INFO\",  # Or REFUTES based on your logic\n","    \"predicted_evidence\": predicted_evidence,\n","\n","}\n","\n","\n","# Get evidence for the claim (adapt this based on your gold standard data format)\n","actual_evidence = []\n","gold_sentences = valid_sentEx[valid_sentEx[\"claim\"] == claim][\"evidence_sentences\"].iloc[0].split('\\n')\n","for sentence in gold_sentences:\n","    for doc in documents:\n","        if sentence in doc:\n","            line_num = doc.split('\\n').index(sentence)\n","            actual_evidence.append([f\"page_{documents.index(doc)}\", line_num])\n","            break\n","\n","# Construct the actual evidence (gold standard) dictionary:\n","\n","actual_instance = {\"label\": label, \"evidence\": [actual_evidence]}\n","\n","# Calculate FEVER score\n","strict_score, label_accuracy, precision, recall, f1 = fever_score([prediction_instance], [actual_instance])\n","fever_results = {\n","    'strict_score': strict_score,\n","    'label_accuracy': label_accuracy,\n","    'precision': precision,\n","    'recall': recall,\n","    'f1': f1\n","}\n","\n","print(\"FEVER Scores:\", fever_results)\n","print(\"-------------------------------------------------------------\")\n","\n","\n","if status == \"OK\":\n","    print(\"Extracted Evidence Sentences:\")\n","    for sentence in extracted_evidence:\n","        print('\\t' + sentence)\n","else:\n","    print(f\"Claim classification: {status}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PERzNad2ISk2"},"outputs":[],"source":["\n","\n","\n","extracted_evidence, status = module_2_semi_supervised_distillation(claim, documents, entities, keywords, verbose=1, debug=True)\n","\n","if status == \"OK\":\n","    print(\"Extracted Evidence Sentences:\")\n","    for sentence in extracted_evidence:\n","        print('\\t' + sentence)\n","    print(f\"Claim classification: {status}\")\n","    print(f\"Label: {label}\")\n","else:\n","    print(f\"Claim classification: {status}\")\n","    print(f\"Label: {label}\")\n","\n","# Evaluation\n","# Assuming you have a gold standard set of sentences for evaluation\n","\n","print(\"Evaluation Scores:\")\n","scores, avg_score = scorer(documents, set(extracted_evidence))\n","for sentence, score in scores.items():\n","    print(f\"Sentence: {sentence}\")\n","    print(f\"Scores: {score}\")\n","    print(\"-------------------------------------------------------------\")\n","print(f\"Average Score: {avg_score}\")  # Adjust based on your scoring logic"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}